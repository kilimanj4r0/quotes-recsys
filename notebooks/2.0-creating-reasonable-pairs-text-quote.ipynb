{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Creating a Dataset of Pairs (diary-style text, quote)","metadata":{}},{"cell_type":"markdown","source":"## 1. Based on Overlapping Emotion Labels of Text and Quote","metadata":{}},{"cell_type":"markdown","source":"Taking the labeled datasets of diaries (diary-style texts) and quotes we can compute most appropriate quote for diary entry. To choose most suitable we will utilize overlapping method. This method include the following comparison of emotion labels of both diary-style text and quote: pick those quote that has maximum overlapping emotion labels (and greater than some score) with diary-style text.  ","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n\ndiaries_dfs = {\n    'reddit': pd.read_csv('../data/diaries_labeled_reddit.csv', index_col=0),\n    'twitter': pd.read_csv('../data/diaries_labeled_twitter.csv', index_col=0),\n}\n# quotes_dfs = {\n#     'reddit': pd.read_csv('../data/.csv', index_col=0),\n#     'twitter': pd.read_csv('../data/.csv', index_col=0),\n# }","metadata":{},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## 2. Based on Embeddings of Text and Quote","metadata":{}},{"cell_type":"markdown","source":"Utilizing embeddings that are learned by chosen classifiers (`roberta-base-go_emotions` and `twitter-roberta-base-emotion-multilabel-latest`) we can compare of embeddings of text and quote. To get embeddings for text and quote we need to turn off the last classification layer from both models. We will use Cosine Similary between embeddings to compare the text and quote. So, top-1 quote by Cosine Similarity (above some threshold) will be chosen for each diary-style text.  ","metadata":{}},{"cell_type":"markdown","source":"### Read the data","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n\n# diaries = pd.read_csv('../data/diaries_labeled_reddit.csv', index_col=0)['Text'].to_list()\n# quotes = pd.read_csv('../data/quotes.csv')['Quote'].to_list()\n\ndiaries = pd.read_csv('/kaggle/input/recsys/diaries_labeled_reddit.csv', index_col=0)['Text'].to_list()\nquotes = pd.read_csv('/kaggle/input/recsys/quotes.csv')['Quote'].to_list()","metadata":{"execution":{"iopub.status.busy":"2023-11-13T22:21:09.411958Z","iopub.execute_input":"2023-11-13T22:21:09.412420Z","iopub.status.idle":"2023-11-13T22:21:09.868832Z","shell.execute_reply.started":"2023-11-13T22:21:09.412392Z","shell.execute_reply":"2023-11-13T22:21:09.867887Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### Load models","metadata":{}},{"cell_type":"code","source":"import torch\n\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-11-13T22:21:13.608481Z","iopub.execute_input":"2023-11-13T22:21:13.609320Z","iopub.status.idle":"2023-11-13T22:21:19.549738Z","shell.execute_reply.started":"2023-11-13T22:21:13.609288Z","shell.execute_reply":"2023-11-13T22:21:19.548812Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoTokenizer, RobertaModel\n\n\ntokenizer_reddit = AutoTokenizer.from_pretrained(\"SamLowe/roberta-base-go_emotions\")\nmodel_reddit = RobertaModel.from_pretrained(\"SamLowe/roberta-base-go_emotions\", add_pooling_layer=False, device_map=\"auto\")\n\ntokenizer_twitter = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-emotion-multilabel-latest\")\nmodel_twitter = RobertaModel.from_pretrained(\"cardiffnlp/twitter-roberta-base-emotion-multilabel-latest\", add_pooling_layer=False, device_map=\"auto\")","metadata":{"execution":{"iopub.status.busy":"2023-11-13T22:21:19.551388Z","iopub.execute_input":"2023-11-13T22:21:19.551806Z","iopub.status.idle":"2023-11-13T22:21:48.068095Z","shell.execute_reply.started":"2023-11-13T22:21:19.551778Z","shell.execute_reply":"2023-11-13T22:21:48.067291Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/380 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05ca46868bbd434989ca9f471475bc1a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3803c971bb684b04b4fd1224109435e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"074c88cf45fc4e8d98af053b0d791443"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"225baf1fd965401e8e73dd2199af1ace"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2682df5dff84ba7ab04f6646fdc95b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/1.92k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecdc5cc3de88451680f4a38eb4aee2e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16d04c4e582f47bb9f8562e554012d83"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/409 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45dff109497b46edad7129fbc16b638f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1513022eb5ba495b9315b3dbb79b9441"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c795c6a04294d729ffa244dd6a39532"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2bdbf3944c8f472e957c0b3f077072cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6cfb8b249a34f04b2391c00bd9fc73e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/1.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"815a23b3aeb649c899e02b5038d29dc4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7a04ab549004a02b0526db6d9a42e0c"}},"metadata":{}}]},{"cell_type":"code","source":"def model_inference(model, tokenizer, text):\n    tokenized_text = tokenizer(text, return_tensors=\"pt\", truncation=True)\n    tokenized_text = tokenized_text.to(device)\n    output = model(**tokenized_text)\n    return output[0][:, 0, :]","metadata":{"execution":{"iopub.status.busy":"2023-11-13T22:21:48.069560Z","iopub.execute_input":"2023-11-13T22:21:48.069957Z","iopub.status.idle":"2023-11-13T22:21:48.074971Z","shell.execute_reply.started":"2023-11-13T22:21:48.069931Z","shell.execute_reply":"2023-11-13T22:21:48.074086Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"#### Test inference and Cosine Similarity computation","metadata":{}},{"cell_type":"code","source":"test_word = 'sunday'\n\nr1 = model_inference(model_reddit, tokenizer_reddit, test_word)\nr2 = model_inference(model_reddit, tokenizer_reddit, test_word)\nt1 = model_inference(model_twitter, tokenizer_twitter, test_word)\nt2 = model_inference(model_twitter, tokenizer_twitter, test_word)","metadata":{"execution":{"iopub.status.busy":"2023-11-13T21:35:37.664252Z","iopub.execute_input":"2023-11-13T21:35:37.664611Z","iopub.status.idle":"2023-11-13T21:35:38.758745Z","shell.execute_reply.started":"2023-11-13T21:35:37.664583Z","shell.execute_reply":"2023-11-13T21:35:38.757998Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from torch.nn import functional as F\n\n\nF.cosine_similarity(r1, r2).data, F.cosine_similarity(t1, t2).data","metadata":{"execution":{"iopub.status.busy":"2023-11-13T21:35:40.495964Z","iopub.execute_input":"2023-11-13T21:35:40.496706Z","iopub.status.idle":"2023-11-13T21:35:40.505886Z","shell.execute_reply.started":"2023-11-13T21:35:40.496670Z","shell.execute_reply":"2023-11-13T21:35:40.504955Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"(tensor([1.], device='cuda:0'), tensor([1.0000], device='cuda:0'))"},"metadata":{}}]},{"cell_type":"markdown","source":"### Create embeddings","metadata":{}},{"cell_type":"code","source":"quotes_emb_reddit = [model_inference(model_reddit, tokenizer_reddit, q) for q in quotes]","metadata":{"execution":{"iopub.status.busy":"2023-11-13T22:22:15.071279Z","iopub.execute_input":"2023-11-13T22:22:15.072221Z","iopub.status.idle":"2023-11-13T22:23:00.168059Z","shell.execute_reply.started":"2023-11-13T22:22:15.072184Z","shell.execute_reply":"2023-11-13T22:23:00.167183Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"import pickle\n\n\nwith open('./quotes_emb_reddit.pickle', 'wb') as handle:\n    pickle.dump(quotes_emb_reddit, handle)","metadata":{"execution":{"iopub.status.busy":"2023-11-13T21:37:26.003111Z","iopub.execute_input":"2023-11-13T21:37:26.003481Z","iopub.status.idle":"2023-11-13T21:37:26.294372Z","shell.execute_reply.started":"2023-11-13T21:37:26.003450Z","shell.execute_reply":"2023-11-13T21:37:26.293552Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"quotes_emb_twitter = [model_inference(model_twitter, tokenizer_twitter, q) for q in quotes]","metadata":{"execution":{"iopub.status.busy":"2023-11-13T22:32:42.734177Z","iopub.execute_input":"2023-11-13T22:32:42.734586Z","iopub.status.idle":"2023-11-13T22:33:00.206729Z","shell.execute_reply.started":"2023-11-13T22:32:42.734544Z","shell.execute_reply":"2023-11-13T22:33:00.205915Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import pickle\n\n\nwith open('./quotes_emb_twitter.pickle', 'wb') as handle:\n    pickle.dump(quotes_emb_twitter, handle)","metadata":{"execution":{"iopub.status.busy":"2023-11-13T21:39:23.866446Z","iopub.execute_input":"2023-11-13T21:39:23.866820Z","iopub.status.idle":"2023-11-13T21:39:24.138653Z","shell.execute_reply.started":"2023-11-13T21:39:23.866781Z","shell.execute_reply":"2023-11-13T21:39:24.137889Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"### Create a Dataset","metadata":{}},{"cell_type":"markdown","source":"For each diary-style text select most closer quote based on the cosine similarity of their embeddings.","metadata":{}},{"cell_type":"code","source":"from torch.nn import functional as F\nimport numpy as np\n\n\nsimilarity_threshold = 0.8","metadata":{"execution":{"iopub.status.busy":"2023-11-13T22:23:17.624168Z","iopub.execute_input":"2023-11-13T22:23:17.624876Z","iopub.status.idle":"2023-11-13T22:23:17.629970Z","shell.execute_reply.started":"2023-11-13T22:23:17.624839Z","shell.execute_reply":"2023-11-13T22:23:17.628956Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"#### Using [SamLowe/roberta-base-go_emotions](https://huggingface.co/SamLowe/roberta-base-go_emotions) model","metadata":{}},{"cell_type":"code","source":"import pickle\n\n\nwith open('./quotes_emb_reddit.pickle', 'rb') as handle:\n    quotes_emb_reddit = pickle.load(handle)","metadata":{"execution":{"iopub.status.busy":"2023-11-13T22:15:16.101501Z","iopub.execute_input":"2023-11-13T22:15:16.102246Z","iopub.status.idle":"2023-11-13T22:15:16.373099Z","shell.execute_reply.started":"2023-11-13T22:15:16.102211Z","shell.execute_reply":"2023-11-13T22:15:16.372286Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"quotes_emb_reddit = np.array([e.cpu().detach().numpy() for e in quotes_emb_reddit])","metadata":{"execution":{"iopub.status.busy":"2023-11-13T22:23:20.313442Z","iopub.execute_input":"2023-11-13T22:23:20.313828Z","iopub.status.idle":"2023-11-13T22:23:20.848092Z","shell.execute_reply.started":"2023-11-13T22:23:20.313799Z","shell.execute_reply":"2023-11-13T22:23:20.847000Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"for d in diaries[:5]:\n    d_emb = model_inference(model_reddit, tokenizer_reddit, d)\n    d_emb = d_emb.squeeze().cpu()\n    q_emb = torch.tensor(quotes_emb_reddit).squeeze(1)\n    similarities = F.cosine_similarity(d_emb, q_emb)\n    top_index = torch.argmax(similarities).item()\n    above_threshold_indices = (similarities > similarity_threshold).nonzero().flatten().tolist()\n    if above_threshold_indices:\n        index = np.random.choice(above_threshold_indices)\n        print(f'random out of {len(above_threshold_indices)}: ', similarities[index].item())\n    else:\n        index = torch.argmax(similarities).item()\n        print('top: ', similarities[index].item())\n    print(d)\n    print()\n    print(quotes[index])\n    print()\n    print()","metadata":{"execution":{"iopub.status.busy":"2023-11-13T22:14:32.967879Z","iopub.execute_input":"2023-11-13T22:14:32.968645Z","iopub.status.idle":"2023-11-13T22:14:33.994871Z","shell.execute_reply.started":"2023-11-13T22:14:32.968610Z","shell.execute_reply":"2023-11-13T22:14:33.993875Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"top:  0.614059567451477\nMy family was the most salient part of my day, since most days the care of my 2 children occupies the majority of my time. They are 2 years old and 7 months and I love them, but they also require so much attention that my anxiety is higher than ever. I am often overwhelmed by the care the require, but at the same, I am so excited to see them hit developmental and social milestones.\n\nI'm possessed by love — but isn't everybody?\n\n\nrandom out of 2:  0.8722858428955078\nYoga keeps me focused. I am able to take some time for me and breath and work my body. This is important because it sets up my mood for the whole day.\n\nI didn’t grow up in a man’s man world. I grew up with my mum and my sister. But I definitely think in the last two years, I’ve become a lot more content with who I am. I think there’s so much masculinity in being vulnerable and allowing yourself to be feminine, and I’m very comfortable with that. Growing up you don’t even know what those things mean. You have this idea of what being masculine is and as you grow up and experience more of the world, you become more comfortable with who you are. Today it’s easier to embrace masculinity in so many different things. I definitely find – through music, writing, talking with friends and being open – that some of the times when I feel most confident is when I’m allowing myself to be vulnerable. It’s something that I definitely try and do.\n\n\nrandom out of 6:  0.864712655544281\nYesterday, my family and I played a bunch of board games. My husband won most of them which is not surprising in the least. We played all sorts of games including Life, Clue, Mouse Trap and more. It was relaxing and such a happy, fun filled moment.\n\nI think I'm dumb\nor maybe just happy\nthink I'm just happy…\n\n\nrandom out of 4:  0.8632637858390808\nYesterday, I visited my parents and had dinner with them.  I hadn't seen them in a few weeks, so it was wonderful to see them and catch up on things.\n\nWe had a beautiful dream and that was all.\n\n\nrandom out of 1:  0.826089084148407\nYesterday, I really felt the importance of my health. I went on a bit longer hike than usual and was very happy that I could do so. It really made me appreciate my health. With all the news of people dying and the tragedy of the Utah family murder in Mexico, it really made me aware of the importance of my own health and well being.\n\nJewish history is full of suffering and terrible sorrow. But it is also full of immeasurable joy. We honor the suffering through remembrance. We honor the joy through celebration.\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"selected_quotes_reddit = []\nrandom_choose_size = []\n\nfor d in diaries:\n    d_emb = model_inference(model_reddit, tokenizer_reddit, d)\n    d_emb = d_emb.squeeze().cpu()\n    q_emb = torch.tensor(quotes_emb_reddit).squeeze(1)\n    similarities = F.cosine_similarity(d_emb, q_emb)\n    top_index = torch.argmax(similarities).item()\n    above_threshold_indices = (similarities > similarity_threshold).nonzero().flatten().tolist()\n    if above_threshold_indices:\n        index = np.random.choice(above_threshold_indices)\n        random_choose_size.append(len(above_threshold_indices))\n    else:\n        index = torch.argmax(similarities).item()\n    selected_quotes_reddit.append(quotes[index])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Random choice: {len(random_choose_size)} / {len(diaries)}, on average from {np.mean(random_choose_size)} samples')","metadata":{"execution":{"iopub.status.busy":"2023-11-13T22:30:57.856559Z","iopub.execute_input":"2023-11-13T22:30:57.857339Z","iopub.status.idle":"2023-11-13T22:30:57.863288Z","shell.execute_reply.started":"2023-11-13T22:30:57.857305Z","shell.execute_reply":"2023-11-13T22:30:57.862037Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Random choice: 1274 / 1648, on average from 4.638932496075353 samples\n","output_type":"stream"}]},{"cell_type":"code","source":"diaries_quotes_reddit = pd.DataFrame(zip(diaries, selected_quotes_reddit), columns=['Text', 'Quote'])\ndiaries_quotes_reddit.to_csv('./diaries_quotes_emb_reddit.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-13T22:31:06.009231Z","iopub.execute_input":"2023-11-13T22:31:06.009925Z","iopub.status.idle":"2023-11-13T22:31:06.057614Z","shell.execute_reply.started":"2023-11-13T22:31:06.009891Z","shell.execute_reply":"2023-11-13T22:31:06.056840Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"#### Using [twitter-roberta-base-emotion-multilabel-latest](https://huggingface.co/cardiffnlp/twitter-roberta-base-emotion-multilabel-latest) model","metadata":{}},{"cell_type":"code","source":"import pickle\n\n\nwith open('./quotes_emb_twitter.pickle', 'rb') as handle:\n    quotes_emb_reddit = pickle.load(handle)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"quotes_emb_twitter = np.array([e.cpu().detach().numpy() for e in quotes_emb_twitter])","metadata":{"execution":{"iopub.status.busy":"2023-11-13T22:33:10.229108Z","iopub.execute_input":"2023-11-13T22:33:10.229846Z","iopub.status.idle":"2023-11-13T22:33:10.801883Z","shell.execute_reply.started":"2023-11-13T22:33:10.229813Z","shell.execute_reply":"2023-11-13T22:33:10.801001Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"for d in diaries[:5]:\n    d_emb = model_inference(model_twitter, tokenizer_twitter, d)\n    d_emb = d_emb.squeeze().cpu()\n    q_emb = torch.tensor(quotes_emb_twitter).squeeze(1)\n    similarities = F.cosine_similarity(d_emb, q_emb)\n    top_index = torch.argmax(similarities).item()\n    above_threshold_indices = (similarities > similarity_threshold).nonzero().flatten().tolist()\n    if above_threshold_indices:\n        index = np.random.choice(above_threshold_indices)\n        print(f'random out of {len(above_threshold_indices)}: ', similarities[index].item())\n    else:\n        index = torch.argmax(similarities).item()\n        print('top: ', similarities[index].item())\n    print(d)\n    print()\n    print(quotes[index])\n    print()\n    print()","metadata":{"execution":{"iopub.status.busy":"2023-11-13T22:33:55.511771Z","iopub.execute_input":"2023-11-13T22:33:55.512388Z","iopub.status.idle":"2023-11-13T22:33:55.647922Z","shell.execute_reply.started":"2023-11-13T22:33:55.512359Z","shell.execute_reply":"2023-11-13T22:33:55.646829Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"random out of 2:  0.9532959461212158\nMy family was the most salient part of my day, since most days the care of my 2 children occupies the majority of my time. They are 2 years old and 7 months and I love them, but they also require so much attention that my anxiety is higher than ever. I am often overwhelmed by the care the require, but at the same, I am so excited to see them hit developmental and social milestones.\n\nYou say you love rain, but you use an umbrella to walk under it. You say you love sun, but you seek shelter when it is shining. You say you love wind, but when it comes you close your windows. So that's why I'm scared when you say you love me.\n\n\nrandom out of 228:  0.9184310436248779\nYoga keeps me focused. I am able to take some time for me and breath and work my body. This is important because it sets up my mood for the whole day.\n\nChange is good only when you know yourself.\n\n\nrandom out of 31:  0.818392813205719\nYesterday, my family and I played a bunch of board games. My husband won most of them which is not surprising in the least. We played all sorts of games including Life, Clue, Mouse Trap and more. It was relaxing and such a happy, fun filled moment.\n\nAlways remember. You will live. You will love. You will dance again.\n\n\nrandom out of 26:  0.8188657760620117\nYesterday, I visited my parents and had dinner with them.  I hadn't seen them in a few weeks, so it was wonderful to see them and catch up on things.\n\nYou know, all that really matters is that the people you love are happy and healthy. Everything else is just sprinkles on the sundae.\n\n\nrandom out of 8:  0.9307577013969421\nYesterday, I really felt the importance of my health. I went on a bit longer hike than usual and was very happy that I could do so. It really made me appreciate my health. With all the news of people dying and the tragedy of the Utah family murder in Mexico, it really made me aware of the importance of my own health and well being.\n\nJewish history is full of suffering and terrible sorrow. But it is also full of immeasurable joy. We honor the suffering through remembrance. We honor the joy through celebration.\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"selected_quotes_twitter = []\nrandom_choose_size = []\n\nfor d in diaries:\n    d_emb = model_inference(model_twitter, tokenizer_twitter, d)\n    d_emb = d_emb.squeeze().cpu()\n    q_emb = torch.tensor(quotes_emb_twitter).squeeze(1)\n    similarities = F.cosine_similarity(d_emb, q_emb)\n    top_index = torch.argmax(similarities).item()\n    above_threshold_indices = (similarities > similarity_threshold).nonzero().flatten().tolist()\n    if above_threshold_indices:\n        index = np.random.choice(above_threshold_indices)\n        random_choose_size.append(len(above_threshold_indices))\n    else:\n        index = torch.argmax(similarities).item()\n    selected_quotes_twitter.append(quotes[index])","metadata":{"execution":{"iopub.status.busy":"2023-11-13T22:34:18.343549Z","iopub.execute_input":"2023-11-13T22:34:18.343883Z","iopub.status.idle":"2023-11-13T22:34:58.391062Z","shell.execute_reply.started":"2023-11-13T22:34:18.343858Z","shell.execute_reply":"2023-11-13T22:34:58.390231Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"print(f'Random choice: {len(random_choose_size)} / {len(diaries)}, on average from {np.mean(random_choose_size)} samples')","metadata":{"execution":{"iopub.status.busy":"2023-11-13T22:34:58.393064Z","iopub.execute_input":"2023-11-13T22:34:58.393501Z","iopub.status.idle":"2023-11-13T22:34:58.399989Z","shell.execute_reply.started":"2023-11-13T22:34:58.393466Z","shell.execute_reply":"2023-11-13T22:34:58.398992Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Random choice: 1627 / 1648, on average from 60.77504609711125 samples\n","output_type":"stream"}]},{"cell_type":"code","source":"diaries_quotes_reddit = pd.DataFrame(zip(diaries, selected_quotes_twitter), columns=['Text', 'Quote'])\ndiaries_quotes_reddit.to_csv('./diaries_quotes_emb_twitter.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-13T22:35:10.541391Z","iopub.execute_input":"2023-11-13T22:35:10.542275Z","iopub.status.idle":"2023-11-13T22:35:10.582003Z","shell.execute_reply.started":"2023-11-13T22:35:10.542238Z","shell.execute_reply":"2023-11-13T22:35:10.581029Z"},"trusted":true},"execution_count":20,"outputs":[]}]}