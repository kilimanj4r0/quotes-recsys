{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T20:54:02.076822Z",
     "start_time": "2023-11-28T20:54:01.784866Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "diaries = pd.read_csv('quotes-recsys/data/diaries_labeled_reddit.csv', index_col=0)['Text'].to_list()[600:670]\n",
    "quotes = pd.read_csv('quotes-recsys/data/quotes.csv')['Quote'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b70a129da90ae1bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T21:10:49.774564Z",
     "start_time": "2023-11-28T21:10:49.772476Z"
    },
<<<<<<< HEAD
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
=======
    "collapsed": false
>>>>>>> ba42a8095f0e13dd8480e2200f60c43b9998e227
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "687cf5429f638e6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T21:11:29.681510Z",
     "start_time": "2023-11-28T21:11:29.677394Z"
    },
<<<<<<< HEAD
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
=======
    "collapsed": false
>>>>>>> ba42a8095f0e13dd8480e2200f60c43b9998e227
   },
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from transformers import AutoTokenizer, RobertaModel, AutoModel\n",
    "\n",
    "\n",
    "class DSSM(nn.Module):\n",
    "    def __init__(self, base_model_name, base_model=AutoModel):\n",
    "        super().__init__()\n",
    "        self.diary_emb = base_model.from_pretrained(base_model_name, add_pooling_layer=False)\n",
    "        self.quote_emb = base_model.from_pretrained(base_model_name, add_pooling_layer=False)\n",
    "\n",
    "    def forward(self, diary, quote):\n",
    "        return self.diary_emb(**diary), self.quote_emb(**quote)\n",
    "\n",
    "def get_models_and_tokenizer(base_model_name, base_model=AutoModel, ckpt=None):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "    model = DSSM(base_model_name, base_model=base_model)\n",
    "    if ckpt:\n",
    "        print(\"use ckpt\")\n",
    "        model.load_state_dict(torch.load(ckpt, map_location=device))\n",
    "    model.to(device)\n",
    "    return model.diary_emb, model.quote_emb, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62516a285b12a5b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T21:07:56.497191Z",
     "start_time": "2023-11-28T21:07:56.488691Z"
    },
<<<<<<< HEAD
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
=======
    "collapsed": false
>>>>>>> ba42a8095f0e13dd8480e2200f60c43b9998e227
   },
   "outputs": [],
   "source": [
    "def model_inference(model, tokenizer, text):\n",
    "    tokenized_text = tokenizer(text, return_tensors=\"pt\", truncation=True)\n",
    "    tokenized_text = tokenized_text.to(device)\n",
    "    output = model(**tokenized_text)\n",
    "    return output[0][:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2aefcb3ba2a4c25b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T20:54:51.872617Z",
     "start_time": "2023-11-28T20:54:51.867999Z"
    },
<<<<<<< HEAD
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
=======
    "collapsed": false
>>>>>>> ba42a8095f0e13dd8480e2200f60c43b9998e227
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "similarity_threshold = 0.8\n",
    "\n",
    "def recommend_quote(diaries, quotes, diary_emb, quote_emb, tokenizer):\n",
    "    quotes_emb = [model_inference(quote_emb, tokenizer, q) for q in tqdm(quotes)]\n",
    "    quotes_emb = np.array([e.cpu().detach().numpy() for e in quotes_emb])\n",
    "    \n",
    "    selected_quotes_twitter = []\n",
    "    random_choose_size = []\n",
    "    \n",
    "    for d in tqdm(diaries):\n",
    "        d_emb = model_inference(diary_emb, tokenizer, d)\n",
    "        d_emb = d_emb.squeeze().cpu()\n",
    "        q_emb = torch.tensor(quotes_emb).squeeze(1)\n",
    "        similarities = F.cosine_similarity(d_emb, q_emb, dim=0)\n",
    "        above_threshold_indices = (similarities > similarity_threshold).nonzero().flatten().tolist()\n",
    "        if above_threshold_indices:\n",
    "            index = np.random.choice(above_threshold_indices)\n",
    "            random_choose_size.append(len(above_threshold_indices))\n",
    "        else:\n",
    "            index = torch.argmax(similarities).item()\n",
    "        selected_quotes_twitter.append(quotes[index])\n",
    "    return selected_quotes_twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acddf28f6d46cc25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T20:56:20.319406Z",
     "start_time": "2023-11-28T20:55:42.103490Z"
    },
<<<<<<< HEAD
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
=======
    "collapsed": false
>>>>>>> ba42a8095f0e13dd8480e2200f60c43b9998e227
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 852/852 [00:07<00:00, 117.26it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 128.93it/s]\n"
     ]
    }
   ],
   "source": [
    "reddit_recommended = recommend_quote(diaries, quotes, *get_models_and_tokenizer(\"SamLowe/roberta-base-go_emotions\", base_model=RobertaModel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7a1463d-bc24-44b9-b1e3-6cbac07b5a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 852/852 [00:05<00:00, 164.71it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 123.57it/s]\n"
     ]
    }
   ],
   "source": [
    "reddit_finetuned_recommended = recommend_quote(diaries, quotes, *get_models_and_tokenizer(\"SamLowe/roberta-base-go_emotions\", base_model=RobertaModel, ckpt=\"go-em.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cb2e8ef86c12ef0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T21:02:17.957550Z",
     "start_time": "2023-11-28T21:01:37.364782Z"
    },
<<<<<<< HEAD
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
=======
    "collapsed": false
>>>>>>> ba42a8095f0e13dd8480e2200f60c43b9998e227
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eff67751ab434def968d35a3d768b8b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/409 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f91c080b098411b96e789d82288d576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fd5c4af38824e5a83a6a6b99d08f634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cceeab44cf814cfdb54df5971f8330a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88b63c49e69646c8bf2e1e7741d8ccaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c90b0f7306bc42058fb13aa9cd5d65fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74b328dbff094337a715522a4873f9ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 852/852 [00:05<00:00, 168.17it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 126.70it/s]\n"
     ]
    }
   ],
   "source": [
    "twitter_recommended = recommend_quote(diaries, quotes, \n",
    "                                      *get_models_and_tokenizer(\"cardiffnlp/twitter-roberta-base-emotion-multilabel-latest\", base_model=RobertaModel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fb7ff00-c99a-4beb-ab8d-fa550ce76679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 852/852 [00:07<00:00, 117.05it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 124.81it/s]\n"
     ]
    }
   ],
   "source": [
    "twitter_finetuned_recommended = recommend_quote(diaries, quotes, \n",
    "                                      *get_models_and_tokenizer(\"cardiffnlp/twitter-roberta-base-emotion-multilabel-latest\", base_model=RobertaModel, ckpt=\"twitter.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db1e72a1f9c68db8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T21:18:51.947422Z",
     "start_time": "2023-11-28T21:18:15.595738Z"
    },
<<<<<<< HEAD
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
=======
    "collapsed": false
>>>>>>> ba42a8095f0e13dd8480e2200f60c43b9998e227
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at BAAI/bge-base-en-v1.5 were not used when initializing BertModel: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at BAAI/bge-base-en-v1.5 were not used when initializing BertModel: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 852/852 [00:05<00:00, 166.78it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 115.35it/s]\n"
     ]
    }
   ],
   "source": [
    "bge_base_recommended = recommend_quote(diaries, quotes, *get_models_and_tokenizer(\"BAAI/bge-base-en-v1.5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a4563aabf50dafb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T21:12:14.913949Z",
     "start_time": "2023-11-28T21:11:33.698930Z"
    },
    "collapsed": false,
<<<<<<< HEAD
    "jupyter": {
     "outputs_hidden": false
    },
=======
>>>>>>> ba42a8095f0e13dd8480e2200f60c43b9998e227
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at BAAI/bge-base-en-v1.5 were not used when initializing BertModel: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at BAAI/bge-base-en-v1.5 were not used when initializing BertModel: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 852/852 [00:05<00:00, 166.34it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 128.64it/s]\n"
     ]
    }
   ],
   "source": [
    "bge_recommended = recommend_quote(diaries, quotes, *get_models_and_tokenizer(\"BAAI/bge-base-en-v1.5\", ckpt=\"bge.pt\"))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
   "id": "da72ba613b496ced",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T20:57:02.883279Z",
     "start_time": "2023-11-28T20:57:02.875644Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = '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'"
   ]
  },
  {
   "cell_type": "code",
=======
>>>>>>> ba42a8095f0e13dd8480e2200f60c43b9998e227
   "execution_count": 11,
   "id": "9f1441bac109d7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T20:57:38.426541Z",
     "start_time": "2023-11-28T20:57:38.403404Z"
    },
<<<<<<< HEAD
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
=======
    "collapsed": false
>>>>>>> ba42a8095f0e13dd8480e2200f60c43b9998e227
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from openai import OpenAI, APITimeoutError\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def evaluate_openai(diaries, selected_quotes, model=\"gpt-4\"):\n",
    "    interactions = []\n",
    "    for i, (d, q) in enumerate(pbar := tqdm(zip(diaries, selected_quotes), total=len(diaries))):\n",
    "        j = 1\n",
    "        while True:\n",
    "            try:\n",
    "                pbar.set_postfix({\"retry\": j})\n",
    "                response = client.chat.completions.create(\n",
    "                    model=model,\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"Imagine you are the primary evaluator of the recommendation system. System recommend quote to the diary text by user (user answers to the question \\\"How was your day?\\\"). The system have cold start problem, that is why we ask you to solve a specific task (will be announced in the next prompt). You have a dataset of pairs (diary text, quote text). The diary texts were collected journal entries from people reflecting on their day. The quote was selected by baseline model that uses cosine similarity distance between embeddings from multi-label (28 emotions) classifier on reddit texts.\"},\n",
    "                        {\"role\": \"user\", \"content\": f'Your task is to evaluate each pair of diary text and quote text how much (in your opinion) the quote fits the corresponding diary, giving a rating of \"1\" - if it fits enough or \"-1\" - if it is not fits enough. Make decisions based on how the quote could lift the mood of the user and mood of most people who would be shown this quote for a similar text. Write ONLY \"1\" or \"-1\"\\n\\nDiary text: {d}\\nQuote text: {q}'}\n",
    "                    ],\n",
    "                    max_tokens=2,\n",
    "                    timeout=5\n",
    "                )\n",
    "                break\n",
    "            except APITimeoutError:\n",
    "                j += 1\n",
    "                pass\n",
    "        \n",
    "        interactions.append(response.choices[0].message.content)\\\n",
    "    \n",
    "    np_interactions = np.array([int(e) for e in interactions])\n",
    "    return (np_interactions == 1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c3bfd4d-20ed-4791-9e8d-755de35f9d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:34<00:00,  2.03it/s, retry=1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.38571428571428573"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_openai(diaries, reddit_recommended, model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "107d6659-c406-4b4a-8edf-9e0a8c17ac94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:33<00:00,  2.08it/s, retry=1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.44285714285714284"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_openai(diaries, reddit_finetuned_recommended, model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf934590-4419-495e-9923-42f72631c6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:33<00:00,  2.08it/s, retry=1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_openai(diaries, twitter_recommended, model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b0dcfc7-3875-4769-ac39-c585bd069415",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:30<00:00,  2.27it/s, retry=1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4857142857142857"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_openai(diaries, twitter_finetuned_recommended, model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "788975521741132c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T21:03:51.835067Z",
     "start_time": "2023-11-28T21:02:48.719126Z"
    },
<<<<<<< HEAD
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
=======
    "collapsed": false
>>>>>>> ba42a8095f0e13dd8480e2200f60c43b9998e227
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:33<00:00,  2.11it/s, retry=1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_openai(diaries, bge_base_recommended, model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1789c1cc-1978-47b0-a188-b097c5ffb5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:42<00:00,  1.65it/s, retry=1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.44285714285714284"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_openai(diaries, bge_recommended, model=\"gpt-3.5-turbo\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
